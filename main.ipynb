{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import signal\n",
    "from pathlib import Path\n",
    "import wget\n",
    "\n",
    "parser_version = '1.6.4'\n",
    "url = f'https://github.com/nemoware/document-parser/releases/download/{parser_version}/document-parser-{parser_version}.jar'\n",
    "if not Path(f'document-parser-{parser_version}.jar').is_file():\n",
    "    wget.download(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import zipfile\n",
    "\n",
    "with zipfile.ZipFile(f'./{glob.glob(\"ДД по практикам*.zip\")[0]}',\n",
    "                     'r') as zip_ref:\n",
    "    zip_ref.extractall('./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "parser_version = '1.6.4'\n",
    "!java -cp \"document-parser-$parser_version/classes;document-parser-$parser_version/lib/*\" com.nemo.document.parser.App -i \"ДД по практикам\\Практика поддержки региональных, розничных продаж и клиентского сервиса\\СОГЛАШЕНИЕ о замене стороны.docx\"\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import platform\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import fnmatch\n",
    "import base64\n",
    "import requests\n",
    "import time\n",
    "\n",
    "index = 1\n",
    "number_of_docs = 0\n",
    "parser_version = '1.6.4'\n",
    "root = \"ДД по практикам\"\n",
    "\n",
    "arrOfAllDocs = []\n",
    "result = []\n",
    "result_of_fail = []\n",
    "paragraph_number = 1\n",
    "s = [\n",
    "    \"java\",\n",
    "    \"-jar\",\n",
    "    f\"document-parser-{parser_version}.jar\",\n",
    "    \"--server.port=8083\"\n",
    "]\n",
    "headers = {\n",
    "    'Content-type': 'application/json',\n",
    "    'Accept': 'application/json; text/plain'\n",
    "}\n",
    "\n",
    "for root, dirnames, filenames in os.walk('ДД по практикам'):\n",
    "    for filename in fnmatch.filter(filenames, '*.docx'):\n",
    "        arrOfAllDocs.append(os.path.join(root, filename))\n",
    "    for filename in fnmatch.filter(filenames, '*.doc'):\n",
    "        arrOfAllDocs.append(os.path.join(root, filename))\n",
    "\n",
    "print(\n",
    "    \"Запуск document-parser на 8083 порту, если что0то пойдет не так, то руками УБЕЙТЕ java процесс\"\n",
    ")\n",
    "java_subprocess = subprocess.Popen(s, creationflags=subprocess.CREATE_NEW_PROCESS_GROUP,\n",
    "                                   stdout=subprocess.PIPE, encoding=\"utf-8\")\n",
    "time.sleep(2)\n",
    "i = 1\n",
    "while True:\n",
    "    time.sleep(0.1)\n",
    "    output_log_spring = java_subprocess.stdout.readline()\n",
    "    sys.stdout.write(\"\\rПроверка соединения #%i\" % i)\n",
    "    sys.stdout.flush()\n",
    "    i += 1\n",
    "    if output_log_spring.find(\n",
    "            \"Started DocumentParserService\") != -1:\n",
    "        print(\"\\nГотово\")\n",
    "        java_subprocess.stdout.close()\n",
    "        break\n",
    "\n",
    "print(\"Запустился успешно\")\n",
    "print(\"Общее количество документов =\", len(arrOfAllDocs))\n",
    "\n",
    "for docs in arrOfAllDocs:\n",
    "    try:\n",
    "        file = open(docs, 'rb')\n",
    "        encoded_string = base64.b64encode(file.read())\n",
    "        encoded_string = str(encoded_string)[2:-1]\n",
    "    except Exception as e:\n",
    "        print(f\"\\nОшибка в файле {docs}\")\n",
    "        print(f\"при конвертации в base64, исключение = {e.msg}\")\n",
    "        print(\"=\" * 200)\n",
    "        continue\n",
    "\n",
    "    response = requests.post(\n",
    "        \"http://localhost:8083/document-parser\",\n",
    "        data=json.dumps({\n",
    "            \"base64Content\": encoded_string,\n",
    "            \"documentFileType\": docs.split(\".\")[-1].upper()\n",
    "        }),\n",
    "        headers=headers\n",
    "    )\n",
    "    resArr = []\n",
    "    try:\n",
    "        resArr = response.json()['documents']\n",
    "    except Exception as e:\n",
    "        print(f\"\\nОшибка в файле {docs}\")\n",
    "        print(f\"Ответ от парсера {response.json()}\")\n",
    "        print(f\"Исключение = {e}\")\n",
    "        print(\"=\" * 200)\n",
    "        continue\n",
    "\n",
    "    sys.stdout.write(f\"\\rПроверка документа под номером {index}\")\n",
    "    sys.stdout.flush()\n",
    "    index += 1\n",
    "\n",
    "    document = []\n",
    "    if resArr:\n",
    "        document = resArr[0]\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "    if document['documentType'] == \"CONTRACT\":\n",
    "        flag = False\n",
    "        for p in document['paragraphs']:\n",
    "            if any(z.lower() in p['paragraphHeader']['text'].lower() for z in [\n",
    "                'ПРЕДМЕТ', 'Общие состояние']) and p['paragraphBody']['length'] > 20:\n",
    "                result.append(\n",
    "                    {\n",
    "                        \"path\": docs,\n",
    "                        \"name\": docs.split(\"\\\\\")[-1],\n",
    "                        \"documentType\": document['documentType'],\n",
    "                        \"offset\": p['paragraphBody']['offset'],\n",
    "                        \"text\": p['paragraphBody']['text'],\n",
    "                        \"length\": p['paragraphBody']['length'],\n",
    "                        \"offsetHeader\": p['paragraphHeader']['offset'],\n",
    "                        \"textHeader\": p['paragraphHeader']['text'],\n",
    "                        \"lengthHeader\": p['paragraphHeader']['length']\n",
    "                    })\n",
    "                flag = True\n",
    "                break\n",
    "\n",
    "        if flag: continue\n",
    "        result_of_fail.append(\n",
    "            {\n",
    "                \"path\": docs,\n",
    "                \"name\": docs.split(\"\\\\\")[-1],\n",
    "                \"documentType\": document['documentType'],\n",
    "                \"offset\": document['paragraphs'][0]['paragraphBody']['offset'],\n",
    "                \"text\": \"\".join(\n",
    "                    str(x['paragraphBody']['text']) for x in document['paragraphs']),\n",
    "                \"length\": sum(i['paragraphBody']['length'] for i in document['paragraphs']),\n",
    "                \"offsetHeader\": document['paragraphs'][0]['paragraphHeader']['offset'],\n",
    "                \"textHeader\": \"\\n+++++++++++++\\n\".join(\n",
    "                    str(x['paragraphHeader']['text']) for x in document['paragraphs']),\n",
    "                \"lengthHeader\": sum(i['paragraphHeader']['length'] for i in document['paragraphs'])\n",
    "            })\n",
    "    elif document['documentType'] == \"SUPPLEMENTARY_AGREEMENT\":\n",
    "        #document['paragraphs'][0]['paragraphHeader']['text']\n",
    "        result.append(\n",
    "            {\n",
    "                \"path\": docs,\n",
    "                \"name\": docs.split(\"\\\\\")[-1],\n",
    "                \"documentType\": document['documentType'],\n",
    "                \"offset\": document['paragraphs'][0]['paragraphBody']['offset'],\n",
    "                \"text\": \"\".join(\n",
    "                    str(x['paragraphBody']['text']) for x in document['paragraphs']),\n",
    "                \"length\": sum(i['paragraphBody']['length'] for i in document['paragraphs']),\n",
    "                \"offsetHeader\": document['paragraphs'][0]['paragraphHeader']['offset'],\n",
    "                \"textHeader\": \"\\n+++++++++++++\\n\".join(\n",
    "                    str(x['paragraphHeader']['text']) for x in document['paragraphs']),\n",
    "                \"lengthHeader\": sum(i['paragraphHeader']['length'] for i in document['paragraphs'])\n",
    "            })\n",
    "    elif document['documentType'] == \"AGREEMENT\":\n",
    "        flag = False\n",
    "        for p in document['paragraphs']:\n",
    "            if any(f.lower() in p['paragraphHeader']['text'].lower() for f in\n",
    "                   ['Предмет соглашения', 'Общие состояние']) and p['paragraphBody']['length'] > 20:\n",
    "                result.append(\n",
    "                    {\n",
    "                        \"path\": docs,\n",
    "                        \"name\": docs.split(\"\\\\\")[-1],\n",
    "                        \"documentType\": document['documentType'],\n",
    "                        \"offset\": p['paragraphBody']['offset'],\n",
    "                        \"text\": p['paragraphBody']['text'],\n",
    "                        \"length\": p['paragraphBody']['length'],\n",
    "                        \"offsetHeader\": p['paragraphHeader']['offset'],\n",
    "                        \"textHeader\": p['paragraphHeader']['text'],\n",
    "                        \"lengthHeader\": p['paragraphHeader']['length']\n",
    "                    })\n",
    "                flag = True\n",
    "                break\n",
    "\n",
    "        if flag: continue\n",
    "\n",
    "        # arr_of_paragraphs[\n",
    "        #     paragraph_number if paragraph_number < len(arr_of_paragraphs) else 0][\n",
    "        #     'paragraphBody']['text'] if\n",
    "        # arr_of_paragraphs[paragraph_number if paragraph_number < len(\n",
    "        #     arr_of_paragraphs) else 0]['paragraphBody']['length'] > 20 else \"\".join(\n",
    "        #     str(x['paragraphBody']['text']) for x in document['paragraphs'])\n",
    "\n",
    "        arr_of_paragraphs = document['paragraphs']\n",
    "        result_of_fail.append(\n",
    "            {\n",
    "                \"path\": docs,\n",
    "                \"name\": docs.split(\"\\\\\")[-1],\n",
    "                \"documentType\": document['documentType'],\n",
    "                \"offset\": arr_of_paragraphs[0]['paragraphBody']['offset'],\n",
    "                \"text\": \"\".join(\n",
    "                    str(x['paragraphBody']['text']) for x in document['paragraphs']),\n",
    "                \"length\": sum(i['paragraphBody']['length'] for i in arr_of_paragraphs),\n",
    "                \"offsetHeader\": arr_of_paragraphs[0]['paragraphHeader']['offset'],\n",
    "                \"textHeader\": \"\\n+++++++++++++\\n\".join(\n",
    "                    str(x['paragraphHeader']['text']) for x in document['paragraphs']),\n",
    "                \"lengthHeader\": sum(i['paragraphHeader']['length'] for i in document['paragraphs'])\n",
    "            })\n",
    "\n",
    "#Смерть java процессу!\n",
    "if platform.system() == 'Windows':\n",
    "    subprocess.run(\"TASKKILL /F /PID {pid} /T\".format(pid=java_subprocess.pid))\n",
    "elif platform.system() == 'Linux':\n",
    "    os.kill(java_subprocess.pid, signal.SIGTERM)\n",
    "else:\n",
    "    print('Не известная платформа')\n",
    "# os.killpg(os.getpgid(java_subprocess.pid), signal.SIGTERM)\n",
    "\n",
    "writer = pd.ExcelWriter(\"classifier.xlsx\", engine='xlsxwriter')\n",
    "\n",
    "df = pd.DataFrame(result)\n",
    "df.to_excel(writer, 'good', engine='xlsxwriter')\n",
    "sheets_good = writer.sheets['good']\n",
    "sheets_good.autofilter(0, 0, df.shape[0], df.shape[1])\n",
    "\n",
    "df = pd.DataFrame(result_of_fail)\n",
    "df.to_excel(writer, 'bad', engine='xlsxwriter')\n",
    "sheets_bad = writer.sheets['bad']\n",
    "sheets_bad.autofilter(0, 0, df.shape[0], df.shape[1])\n",
    "\n",
    "writer.save()\n",
    "print(\"\\nФайл создан\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Копия блокнота \"Test document-parser.ipynb\"",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
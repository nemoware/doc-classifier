{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import signal\n",
    "from pathlib import Path\n",
    "\n",
    "import wget\n",
    "\n",
    "parser_version = '1.6.7'\n",
    "url = f'https://github.com/nemoware/document-parser/releases/download/{parser_version}/document-parser-{parser_version}.jar'\n",
    "if not Path(f'document-parser-{parser_version}.jar').is_file():\n",
    "    wget.download(url)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import glob\n",
    "import zipfile\n",
    "\n",
    "with zipfile.ZipFile(f'./{glob.glob(\"ДД по практикам*.zip\")[0]}',\n",
    "                     'r') as zip_ref:\n",
    "    zip_ref.extractall('./')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "parser_version = '1.6.7'\n",
    "!java -cp \"document-parser-$parser_version/classes;document-parser-$parser_version/lib/*\" com.nemo.document.parser.App -i \"Документы\\ДД по практикам\\Практика правового сопровождения закупок МТР и услуг общего профиля\\ДД ООО И.doc\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Start"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import platform\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import fnmatch\n",
    "import base64\n",
    "import requests\n",
    "import time\n",
    "import importlib\n",
    "import logging\n",
    "import search_text\n",
    "import search_text_v2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create list of all docs path"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "arrOfAllDocs = []\n",
    "\n",
    "for root, dir_names, filenames in os.walk('Документы'):\n",
    "    if len(root.split('\\\\')) == 2: continue\n",
    "    flag = False\n",
    "    for i in root.split('\\\\'):\n",
    "        if str(i).startswith('Исключена'):\n",
    "            flag = True\n",
    "            break\n",
    "    if flag: continue\n",
    "    for filename in fnmatch.filter(filenames, '*.docx'):\n",
    "        arrOfAllDocs.append(os.path.join(root, filename))\n",
    "    for filename in fnmatch.filter(filenames, '*.doc'):\n",
    "        arrOfAllDocs.append(os.path.join(root, filename))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "arrOfAllDocs[:]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "\n",
    "def driver_func(documents, path):\n",
    "    processes = 4\n",
    "    with multiprocessing.Pool(processes) as pool:\n",
    "        params = zip(documents, path)\n",
    "        print(params)\n",
    "        results = [pool.apply_async(search_text_v2.get_text, param) for param in params]\n",
    "\n",
    "        for r in results:\n",
    "            print('\\t', r.get())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "importlib.reload(search_text)\n",
    "importlib.reload(search_text_v2)\n",
    "\n",
    "index = 1\n",
    "number_of_docs = 0\n",
    "parser_version = '1.6.7'\n",
    "\n",
    "labels = ['Практика коммерческой логистики',\n",
    "          'Практика недропользования и экологии',\n",
    "          'Практика поддержки региональных, розничных продаж и клиентского сервиса',\n",
    "          'Практика правового сопровождения закупок МТР и услуг общего профиля',\n",
    "          'Практика правового сопровождения земельных отношений и сделок с недвижимым имуществом',\n",
    "          'Практика правового сопровождения операционной деятельности БРД',\n",
    "          'Практика правового сопровождения переработки и инфраструктуры',\n",
    "          'Практика правовой поддержки брендов',\n",
    "          'Практика правовой поддержки использования и коммерциализации ИС',\n",
    "          'Практика правовой поддержки создания и приобретения ИС',\n",
    "          'Практика промышленной безопасности и охраны труда',\n",
    "          'Практика финансового и конкурентного права',\n",
    "          'Практика экспорта, оптовых продаж и сбыта бизнес-единиц (БЕ)']\n",
    "\n",
    "result = []\n",
    "result_of_fail = []\n",
    "result_of_possible = []\n",
    "result_of_possible2 = []\n",
    "\n",
    "s = [\n",
    "    \"java\",\n",
    "    \"-jar\",\n",
    "    f\"document-parser-{parser_version}.jar\",\n",
    "    \"--server.port=8083\"\n",
    "]\n",
    "headers = {\n",
    "    'Content-type': 'application/json',\n",
    "    'Accept': 'application/json; text/plain'\n",
    "}\n",
    "\n",
    "parser_url = \"http://localhost:8083/\"\n",
    "java_subprocess = None\n",
    "try:\n",
    "    i = 1\n",
    "    try:\n",
    "        print(f\"Проверка, если парсер заупущен на {parser_url}\")\n",
    "        response = requests.post(\n",
    "            f\"{parser_url}status\",\n",
    "            headers=headers\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(\n",
    "            \"Запуск document-parser на 8083 порту, если что-то пойдет не так, то руками УБЕЙТЕ java процесс\"\n",
    "        )\n",
    "        java_subprocess = subprocess.Popen(s, creationflags=subprocess.CREATE_NEW_PROCESS_GROUP,\n",
    "                                           stdout=subprocess.PIPE, encoding=\"utf-8\")\n",
    "        time.sleep(2)\n",
    "        while True:\n",
    "            # time.sleep(0.1)\n",
    "            output_log_spring = java_subprocess.stdout.readline()\n",
    "            sys.stdout.write(\"\\rПроверка соединения\")\n",
    "            sys.stdout.flush()\n",
    "            i += 1\n",
    "            if output_log_spring.find(\"Started DocumentParserService\") != -1:\n",
    "                print(\"\\nГотово\")\n",
    "                java_subprocess.stdout.close()\n",
    "                break\n",
    "            if i > 31:\n",
    "                raise Exception(\"Не удалось получить доступ к ранее запущенному парсеру\")\n",
    "    print(\"Запустился успешно\")\n",
    "    print(\"Общее количество документов =\", len(arrOfAllDocs))\n",
    "\n",
    "    for docs in arrOfAllDocs:\n",
    "        try:\n",
    "            file = open(docs, 'rb')\n",
    "            encoded_string = base64.b64encode(file.read())\n",
    "            encoded_string = str(encoded_string)[2:-1]\n",
    "        except Exception as e:\n",
    "            # print(f\"\\nОшибка в файле {docs}\")\n",
    "            # print(f\"при конвертации в base64, исключение = {e.msg}\")\n",
    "            # print(\"=\" * 200)\n",
    "            continue\n",
    "        is_doc = True\n",
    "        is_docx = True\n",
    "        is_not_bad_doc = True\n",
    "        doc_type = docs.split(\".\")[-1].upper()\n",
    "        resArr = []\n",
    "        document = []\n",
    "        while is_doc or is_docx or is_not_bad_doc:\n",
    "            response = requests.post(\n",
    "                f\"{parser_url}document-parser\",\n",
    "                data=json.dumps({\n",
    "                    \"base64Content\": encoded_string,\n",
    "                    \"documentFileType\": doc_type\n",
    "                }),\n",
    "                headers=headers\n",
    "            )\n",
    "            if 'message' in response.json() and not (is_doc == False and is_docx == False):\n",
    "                if doc_type == 'DOC':\n",
    "                    is_doc = False\n",
    "                    doc_type = 'DOCX'\n",
    "                    continue\n",
    "                if doc_type == 'DOCX':\n",
    "                    is_docx = False\n",
    "                    doc_type = 'DOC'\n",
    "                    continue\n",
    "\n",
    "            try:\n",
    "                resArr = response.json()['documents']\n",
    "            except Exception as e:\n",
    "                # print(f\"\\nОшибка в файле {docs}\")\n",
    "                # print(f\"Ответ от парсера {response.json()}\")\n",
    "                # print(\"=\" * 200)\n",
    "                continue\n",
    "            finally:\n",
    "                is_doc = False\n",
    "                is_docx = False\n",
    "                is_not_bad_doc = False\n",
    "\n",
    "        sys.stdout.write(\n",
    "            f\"\\rNow {index} from {len(arrOfAllDocs)} и Good = {len(result)}, Bad = {len(result_of_fail)}, TEST = {len(result_of_possible)}, TEST2 = {len(result_of_possible2)}\")\n",
    "        sys.stdout.flush()\n",
    "        index += 1\n",
    "\n",
    "        if not resArr:\n",
    "            continue\n",
    "        # driver_func(resArr, docs)\n",
    "        for document in resArr:\n",
    "            # result_of_single_doc, enum = search_text.find_text(document, path=docs)\n",
    "            result_of_single_doc, enum = search_text_v2.get_text(document, path=docs)\n",
    "\n",
    "            if enum == search_text_v2.list_of_sheets.GOOD:\n",
    "                result.append(result_of_single_doc)\n",
    "            if enum == search_text_v2.list_of_sheets.BAD:\n",
    "                result_of_fail.append(result_of_single_doc)\n",
    "            if enum == search_text_v2.list_of_sheets.BAD2:\n",
    "                result_of_possible.append(result_of_single_doc)\n",
    "            if enum == search_text_v2.list_of_sheets.GOOD2:\n",
    "                result.append(result_of_single_doc)\n",
    "                result_of_possible2.append(result_of_single_doc)\n",
    "\n",
    "    with pd.ExcelWriter(\"classifier.xlsx\", engine=\"xlsxwriter\",\n",
    "                        engine_kwargs={'options': {'strings_to_urls': False}}) as writer:\n",
    "        # writer = pd.ExcelWriter(\"classifier.xlsx\", engine='xlsxwriter')\n",
    "\n",
    "        df = pd.DataFrame(result)\n",
    "        df = df.drop_duplicates(subset=['text'])\n",
    "        df.to_excel(writer, 'good', engine='xlsxwriter')\n",
    "        sheets_good = writer.sheets['good']\n",
    "        sheets_good.autofilter(0, 0, df.shape[0], df.shape[1])\n",
    "\n",
    "        df = pd.DataFrame(result_of_fail)\n",
    "        df.to_excel(writer, 'SO SO', engine='xlsxwriter')\n",
    "        sheets_bad = writer.sheets['SO SO']\n",
    "        sheets_bad.autofilter(0, 0, df.shape[0], df.shape[1])\n",
    "        logging.info(\"\\nФайл создан\")\n",
    "except Exception as e:\n",
    "    logging.error(e)\n",
    "finally:\n",
    "    #Смерть java процессу!\n",
    "    if java_subprocess is not None:\n",
    "        if platform.system() == 'Windows':\n",
    "            subprocess.run(\"TASKKILL /F /PID {pid} /T\".format(pid=java_subprocess.pid))\n",
    "        elif platform.system() == 'Linux':\n",
    "            os.kill(java_subprocess.pid, signal.SIGTERM)\n",
    "        else:\n",
    "            print('Не известная платформа, убейте в ручную процесс java')\n",
    "# Now 2277 from 2277 и Good = 2970, Bad = 52, TEST = 846, TEST2 = 2053"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.read_excel(open('classifier.xlsx', 'rb'), sheet_name='good', index_col=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df[df['text'].apply(lambda x: not isinstance(x, str))]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Копия блокнота \"Test document-parser.ipynb\"",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}